# Система сбора логов

## Введение

Централизованная система сбора логов — это платформа для агрегации, хранения и анализа логов из множества источников (приложения, серверы, контейнеры, базы данных).

В рамках курсовой работы требуется реализовать прототип системы сбора логов, способный принимать логи различных форматов, индексировать их и предоставлять возможность поиска и анализа.

## Цель работы

Создать работающий прототип системы сбора логов, способный:

- собирать логи из разных источников и форматов
- парсить и структурировать логи
- индексировать данные для быстрого поиска
- обнаруживать аномалии и ошибки
- визуализировать метрики в аналитических дашбордах

## Постановка задачи

### Сбор данных

Необходимо реализовать получение логов из трёх разных источников:

- файл .log/.txt/.csv/.json
- HTTP
- Брокер сообщений

Система должна поддерживать разные форматы логов:

- JSON (структурированные логи)
- Syslog format (RFC5424)
- CLF (Common Log Format)

#### Генерация данных

В вашем проекте должны быть **файлы** с тестовыми логами для импорта в хранилище.

Помимо этого, система должна получать логи в реальном времени через брокер сообщений (Kafka/RabbitMQ) от генератора, запущенного в фоне и имитирующего работающие приложения, пишущие логи.

### Хранение данных

#### Примерная схема лога

> Может быть доработана на ваше усмотрение

- `id` *UInt64* — уникальный идентификатор лог-записи
- `created_at` *DateTime* — время создания лога (время создания в источнике)
- `received_at` *DateTime* — время получения системой
- `level` *UInt8*/*String* — уровень (Critical, Info, Error, Warning, Debug и др.)
- `source` *String* — источник лога (имя сервиса/приложения)
- `host` *String* — хост, с которого пришел лог
- `environment` *String* — окружение (dev/staging/production)
- `message` *String* — основное сообщение лога
- `payload` *JSON* — дополнительные структурированные данные
  - `user_id` *UInt64* — пользователь, если применимо
  - `duration_ms` *UInt32* — длительность операции
  - `http_status_code` *UInt16* — HTTP-код статуса запрос (200, 404 и др.)
  - `error_type` *String* — тип ошибки (логическая/исключение/паника и т.д.)
  - `stack_trace` *String* — стек-трейс ошибки (необязательно)

### REST API для взаимодействия с приложением

> Должно быть, **как минимум**, **2 эндпоинта**.
> Можно добавлять и другие на свое усмотрение, например, для удобства отладки или демонстрации работы.

#### Добавление логов

`POST /logs`

Принимает один или несколько логов.

Пример запроса:

```json
[
    {
        "created_at": "2025-01-01T12:00:00Z",
        "level": "error",
        "source": "payment-service",
        "host": "prod-server-01.com",
        "environment": "production",
        "message": "Payment processing failed",
        "payload": {
            "user_id": 1001,
            "http_status_code": 504,
            "error_type": "TimeoutException",
            "duration_ms": 5000
        }
    }
]
```

#### Поиск логов

`GET /logs/search`

Получение логов по фильтрам с пагинацией.

Пример запроса:

```plaintext
GET /logs/level=error&source=payment-service&from=2025-01-01T00:00:00Z&to=2025-01-02T00:00:00Z&limit=100&offset=0
```

> ❗️ Реализуйте фильтрацию по тексту сообщения в логах

Пример ответа:

```json
{
    "total": 42,
    "logs": [
        {
            "id": 123456,
            "created_at": "2025-01-01T12:00:00Z",
            "level": "error",
            "source": "payment-service",
            "message": "Payment processing failed",
            "payload": {
                "error_type": "TimeoutException"
            }
        }
    ]
}
```

### Мониторинг

Используйте [Prometheus](https://prometheus.io/), [Grafana](https://grafana.com/)
для настройки мониторинга работы сервиса и инфраструктуры.

> Метрики мониторинга могут быть кастомизированы на ваше усмотрение

Рекомендуется настроить

- RPS приложения, response time, latency
- Время парсинга логов (min, avg, max)
- Использование ресурсов (CPU, оперативная и постоянная память, сеть)
- Статус компонентов системы (БД, брокеры и т.д.)

### ETL-пайплайн

> Может быть доработан на ваше усмотрение

Ожидается, как минимум, 1 DAG, который:

- Загружает сырые логи из источников в хранилище
- Парсит логи по формату (см. [выше](#сбор-данных))
- Валидирует и очищает данные (удаление дубликатов, проверка обязательных полей)
- Строит агрегированные метрики

### Аналитический дашборд

#### Инструменты

- Apache Superset (предпочтительнее)
- Metabase
- Grafana (при большом желании)

#### Обязательные чарты

- Общее количество логов по времени
- Распределение логов по уровням
- Топ-10 источников логов
- Топ-3 типов ошибок
- Топ-3 ошибок по источникам
- Аномальный рост ошибок (какой-то сервис начал писать очень много ошибок)
- Dead service detection: отображение источников, не пишущие логи более 1 часа

## Минимальные требования

- Сгенерировать **не менее 200 000 логов**
- 3 источника данных
  - файлы
  - HTTP
  - брокер сообщений
- Хранилище
- ETL-пайплайн
- Витрины
- Аналитический дашборд
